{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Prediction for Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Models (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kikimeow\\Anaconda3\\envs\\tf\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import time \n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.externals import joblib\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(model, X_test):\n",
    "    '''\n",
    "    make submission file\n",
    "    arguments:    model = model name \n",
    "                  X_test= X_test name\n",
    "    return: a file saved in directory with timestamp\n",
    "    '''\n",
    "    # model prediction\n",
    "    pred = model.predict(X_test)\n",
    "    print('mean before clipping: ', pred.mean())\n",
    "    pred = pred.clip(0,20)\n",
    "    print('mean after clipping: ', pred.mean())\n",
    "\n",
    "    # create prediction dataframe\n",
    "    ID = joblib.load('ID.pkl')\n",
    "    predDF = pd.DataFrame() \n",
    "    predDF['ID'] = ID\n",
    "    predDF['item_cnt_month'] = pred\n",
    "    print(predDF.head())\n",
    "\n",
    "    # write dataframe to csv\n",
    "    ts = time.time()\n",
    "    st = datetime.datetime.fromtimestamp(ts).strftime('%m%d_%H.%M')\n",
    "    print('submission_' + st + '.csv')\n",
    "    \n",
    "    predDF.to_csv(header=True, index=False, path_or_buf = 'submission_' + st + '.csv')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../data/'\n",
    "X_train= pd.read_pickle(DATA_FOLDER+'X_train_lev_1_standardScaler')\n",
    "y_train = joblib.load(DATA_FOLDER+'y_train_lev_1.pkl')\n",
    "X_test = pd.read_pickle(DATA_FOLDER+'X_test_lev_1_standardScaler')\n",
    "y_test = joblib.load(DATA_FOLDER+'y_val_lev_1.pkl')\n",
    "X_train_full = pd.read_pickle(DATA_FOLDER+'X_train_standardScaler')\n",
    "X_test_full = pd.read_pickle(DATA_FOLDER+'X_test_standardScaler')\n",
    "y_train_full = joblib.load(DATA_FOLDER+'y_train_full.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample 20% of all items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleSize = 0.01 # 33 items\n",
    "sample= list(X_train['item_id'].unique()) + list(X_test['item_id'].unique()) \n",
    "sample = list(set(sample))\n",
    "np.random.seed(1234)\n",
    "sample= list(np.random.choice(sample, size= int(len(sample)*sampleSize), replace=False, p=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Narrow down the training set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop = True)\n",
    "X_test = X_test.reset_index(drop = True)\n",
    "\n",
    "trainIndex = X_train.loc[(X_train['item_id'].isin(sample))].index\n",
    "testIndex = X_test.loc[(X_test['item_id'].isin(sample))].index\n",
    "\n",
    "X_train_s = X_train.loc[trainIndex]\n",
    "X_test_s = X_test.loc[testIndex]\n",
    "y_train_s = y_train[trainIndex]\n",
    "y_test_s = y_test[testIndex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s_m = X_train_s.as_matrix(columns= X_train_s.columns)\n",
    "X_test_m = X_test.as_matrix(columns = X_test_s.columns)\n",
    "X_train_m = X_train.as_matrix(columns= X_train.columns)\n",
    "X_train_full_m = X_train_full.as_matrix(columns = X_train_full.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11354, 235)\n",
      "(43344, 235)\n",
      "11354\n",
      "43344\n",
      "(6425094, 235)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_s_m.shape)\n",
    "print(X_test_m.shape)\n",
    "print(y_train_s.size)\n",
    "print(y_test.size)\n",
    "print(X_train_full_m.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=235, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(32, kernel_initializer='normal'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model Checkpoint: saves the model weights after each epoch if the validation loss decreased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath= 'nnBestModel.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=False,\n",
    "                             mode='auto')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Early Stopping: Stop training when a monitored quantity has stopped improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', \n",
    "                           min_delta = 0.0001, #minimum change in the monitored quantity to qualify as an improvement,\n",
    "                           patience= 5, #number of epochs with no improvement after which training will be stopped.\n",
    "                           mode='auto') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1215879 samples, validate on 43387 samples\n",
      "Epoch 1/50\n",
      "1215685/1215879 [============================>.] - ETA: 0s - loss: 0.7433\n",
      "Epoch 00001: val_loss improved from 0.90202 to 0.83240, saving model to nnBestModel.hdf5\n",
      "1215879/1215879 [==============================] - 277s 228us/step - loss: 0.7433 - val_loss: 0.8324\n",
      "Epoch 2/50\n",
      "1215660/1215879 [============================>.] - ETA: 0s - loss: 0.6898\n",
      "Epoch 00002: val_loss did not improve\n",
      "1215879/1215879 [==============================] - 278s 229us/step - loss: 0.6899 - val_loss: 0.8459\n",
      "Epoch 3/50\n",
      "1215770/1215879 [============================>.] - ETA: 0s - loss: 0.6681\n",
      "Epoch 00003: val_loss did not improve\n",
      "1215879/1215879 [==============================] - 278s 229us/step - loss: 0.6681 - val_loss: 0.8485\n",
      "Epoch 4/50\n",
      "1215780/1215879 [============================>.] - ETA: 0s - loss: 0.6515- ETA: 0s - loss:\n",
      "Epoch 00004: val_loss did not improve\n",
      "1215879/1215879 [==============================] - 271s 223us/step - loss: 0.6515 - val_loss: 0.8343\n",
      "Epoch 5/50\n",
      "1215805/1215879 [============================>.] - ETA: 0s - loss: 0.6428\n",
      "Epoch 00005: val_loss did not improve\n",
      "1215879/1215879 [==============================] - 281s 231us/step - loss: 0.6428 - val_loss: 0.8701\n",
      "Epoch 6/50\n",
      "1215720/1215879 [============================>.] - ETA: 0s - loss: 0.6373\n",
      "Epoch 00006: val_loss did not improve\n",
      "1215879/1215879 [==============================] - 303s 249us/step - loss: 0.6372 - val_loss: 0.9543\n"
     ]
    }
   ],
   "source": [
    "callbacks_list = [checkpoint, early_stop]\n",
    "model = KerasRegressor(build_fn=base_model, verbose= True)\n",
    "history = model.fit(X_train_m, y_train, validation_data=(X_test_m, y_test), epochs=50, batch_size=5, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load previously trained model Weights (the best model from before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43387/43387 [==============================] - 1s 23us/step\n",
      "0.8323987960203406\n",
      "Test_sample MSE: 0.8323988\n",
      "Test_sample RMSE: 0.9123589\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"nnBestModel.hdf5\")\n",
    "scores = model.evaluate(X_test_m, y_test)\n",
    "print(scores)\n",
    "MSE = mean_squared_error(y_test, model.predict(X_test_m))\n",
    "RMSE = np.sqrt(MSE)\n",
    "print('Test_sample MSE:', MSE)\n",
    "print('Test_sample RMSE:', RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit Model (trained on subset of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean before clipping:  0.35371935\n",
      "mean after clipping:  0.359124\n",
      "   ID  item_cnt_month\n",
      "0   0        0.445329\n",
      "1   1        0.329181\n",
      "2   2        0.749330\n",
      "3   3        0.571687\n",
      "4   4        5.889728\n",
      "submission_0130_15.35.csv\n"
     ]
    }
   ],
   "source": [
    "submission(model, X_test_full) # 0.96402"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on full set of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "6425094/6425094 [==============================] - 1300s 202us/step - loss: 0.7505\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'KerasRegressor' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-fdc2cf38b76b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKerasRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_full_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_full\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nn_full_model.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasRegressor' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "model = KerasRegressor(build_fn=base_model, verbose= True)\n",
    "model.fit(X_train_full_m, y_train_full, epochs = 1, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214200/214200 [==============================] - 3s 14us/step\n",
      "mean before clipping:  0.17258075\n",
      "mean after clipping:  0.24591118\n",
      "   ID  item_cnt_month\n",
      "0   0        0.299153\n",
      "1   1        0.369452\n",
      "2   2        0.851133\n",
      "3   3        0.298807\n",
      "4   4        5.882136\n",
      "submission_0131_19.37.csv\n"
     ]
    }
   ],
   "source": [
    "submission(model, X_test_full) # 0.94596"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.save('nn_full_model.h5') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
