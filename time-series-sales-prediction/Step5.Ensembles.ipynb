{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Prediction for Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook gathers predictions from the three base models and train the stacked model.  For this project, the simple averaging of the model predictions did better than stacking.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions for date block 32 will be gathered from the models trained previously, which includes linear regression, light GBM, and neural networks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kikimeow\\Anaconda3\\envs\\tf\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import time \n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.externals import joblib\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "import lightgbm as lgb\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the base model files trained on date_block_num from 12 to 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../script/'\n",
    "lrModel = joblib.load(DATA_FOLDER + 'lr_robust_scale_0201_15.05.pkl') \n",
    "lgbmModel = lgb.Booster(model_file='lgb_model_0131_17.30.txt') \n",
    "nnModel = load_model(DATA_FOLDER + \"nnBestModel.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the X_test and y_test for obtaining predictions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date_block_num = 32.  Used for meta model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../data/'\n",
    "X_test_robustScaler = pd.read_pickle(DATA_FOLDER + 'X_test_lev_1_RobustScaler') # LR\n",
    "X_test_standardScaler = pd.read_pickle(DATA_FOLDER + 'X_test_lev_1_standardScaler') # NNet\n",
    "X_test_robustScalerTree = pd.read_pickle(DATA_FOLDER + 'X_test_lev_1_RobustScalerTree') #light GBM\n",
    "y_test = joblib.load(DATA_FOLDER + 'y_val_lev_1.pkl')\n",
    "X_test_robustScaler_lr = X_test_robustScaler.drop(['shop_id','item_id', 'item_category_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date_block_num = 33.  Used for meta model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../data/'\n",
    "X_test_2_RobustScaler = pd.read_pickle(DATA_FOLDER + 'X_test_lev_2_RobustScaler') # LR\n",
    "X_test_2_standardScaler = pd.read_pickle(DATA_FOLDER + 'X_test_lev_2_standardScaler') # NNet\n",
    "X_test_2_robustScalerTree = pd.read_pickle(DATA_FOLDER + 'X_test_lev_2_RobustScalerTree') #light GBM\n",
    "y_test_2 = joblib.load(DATA_FOLDER + 'y_val_lev_2.pkl')\n",
    "X_test_2_robustScaler_lr = X_test_2_RobustScaler.drop(['shop_id','item_id', 'item_category_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather predictions from base models. \n",
    "These are the meta features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrPred = lrModel.predict(X_test_robustScaler_lr.values).clip(0,20)\n",
    "lgbmPred = lgbmModel.predict(X_test_robustScalerTree.values).clip(0,20)\n",
    "nnPred = nnModel.predict(X_test_standardScaler.values).clip(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrPred_val = lrModel.predict(X_test_2_robustScaler_lr.values).clip(0,20)\n",
    "lgbmPred_val = lgbmModel.predict(X_test_2_robustScalerTree.values).clip(0,20)\n",
    "nnPred_val = nnModel.predict(X_test_2_standardScaler.values).clip(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(columns = ['lr', 'lgbm', 'nnet'])\n",
    "preds['lr'] = lrPred\n",
    "preds['lgbm'] = lgbmPred\n",
    "preds['nnet'] = nnPred\n",
    "preds['mean'] = pd.DataFrame.mean(preds, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val = pd.DataFrame(columns = ['lr', 'lgbm', 'nnet'])\n",
    "preds_val['lr'] = lrPred_val\n",
    "preds_val['lgbm'] = lgbmPred_val\n",
    "preds_val['nnet'] = nnPred_val\n",
    "preds_val['mean'] = pd.DataFrame.mean(preds_val, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_meta = preds.iloc[:,0:4]\n",
    "y_train_meta = y_test\n",
    "X_test_meta = preds_val.iloc[:, 0:4]\n",
    "y_test_meta = y_test_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline:  mean prediction from the base models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base models were trained with data before date_block_num 32.  Below we calculate the MSE for block_num 32.  The meta model's training MSE should be better than these MSE.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 1.3378885 light gbm:  1.5158774749749127 neural netowrks: 1.2493004\n",
      "mean MSE of all models:  1.255182221247377\n"
     ]
    }
   ],
   "source": [
    "lrMSE = mean_squared_error(y_test, lrPred)\n",
    "lgbmMSE = mean_squared_error(y_test, lgbmPred)\n",
    "nnMSE = mean_squared_error(y_test, nnPred)\n",
    "meanMSE = mean_squared_error(y_test, preds['mean'])\n",
    "print('lr:', lrMSE, 'light gbm: ', lgbmMSE, 'neural netowrks:', nnMSE)\n",
    "print('mean MSE of all models: ', meanMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date_block_num 33 is used for validation of the meta model.  Below we calculate the MSE using the base models for this block. The meta model's testing performance should be better than these numbers.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.7841173 light gbm:  1.0244859643995765 neural netowrks: 0.9388006\n",
      "mean MSE of all models:  0.7606538814281627\n"
     ]
    }
   ],
   "source": [
    "lrMSE = mean_squared_error(y_test_2, lrPred_val)\n",
    "lgbmMSE = mean_squared_error(y_test_2, lgbmPred_val)\n",
    "nnMSE = mean_squared_error(y_test_2, nnPred_val)\n",
    "meanMSE = mean_squared_error(y_test_2, preds_val['mean'])\n",
    "print('lr:', lrMSE, 'light gbm: ', lgbmMSE, 'neural netowrks:', nnMSE)\n",
    "print('mean MSE of all models: ',meanMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Meta Model Train (block 32) MSE:  1.0863823291453925\n",
      "Linear Regression Meta Model Test (block 33) MSE:  0.9168139375772854\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.LinearRegression(n_jobs = 4)\n",
    "model.fit(X_train_meta, y_train_meta)\n",
    "lr_meta_test_pred = model.predict(X_test_meta.values)\n",
    "lr_meta_train_pred = model.predict(X_train_meta.values)\n",
    "lr_meta_test_MSE = mean_squared_error(y_test_meta, lr_meta_test_pred.clip(0, 20))\n",
    "lr_meta_train_MSE = mean_squared_error(y_train_meta, lr_meta_train_pred.clip(0, 20))\n",
    "print('Linear Regression Meta Model Train (block 32) MSE: ',lr_meta_train_MSE)\n",
    "print('Linear Regression Meta Model Test (block 33) MSE: ',lr_meta_test_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lr_meta_0201_21.09.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = datetime.datetime.fromtimestamp(time.time()).strftime('%m%d_%H.%M')\n",
    "joblib.dump(model, 'lr_meta_' + st + '.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(params):\n",
    "    lgb_model = lgb.train(params, train_data, valid_sets=[train_data, test_data], verbose_eval=25)\n",
    "    return lgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'application':'regression',\n",
    "    'learning_rate':0.001,\n",
    "    'early_stopping_round':10,\n",
    "    'metric':'l2_root', #RMSE\n",
    "    'nthread':-1, \n",
    "    'train_metric': True,\n",
    "    'num_boost_round': 1000,\n",
    "    'max_depth:': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train_meta, label= y_train_meta)\n",
    "test_data = lgb.Dataset(X_test_meta, label = y_test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kikimeow\\Anaconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\engine.py:98: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\kikimeow\\Anaconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\engine.py:103: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds.\n",
      "[25]\ttraining's rmse: 1.45944\tvalid_1's rmse: 1.12902\n",
      "[50]\ttraining's rmse: 1.43986\tvalid_1's rmse: 1.11237\n",
      "[75]\ttraining's rmse: 1.42098\tvalid_1's rmse: 1.09665\n",
      "[100]\ttraining's rmse: 1.40278\tvalid_1's rmse: 1.08182\n",
      "[125]\ttraining's rmse: 1.38525\tvalid_1's rmse: 1.06789\n",
      "[150]\ttraining's rmse: 1.36835\tvalid_1's rmse: 1.05483\n",
      "[175]\ttraining's rmse: 1.35208\tvalid_1's rmse: 1.04256\n",
      "[200]\ttraining's rmse: 1.33641\tvalid_1's rmse: 1.03109\n",
      "[225]\ttraining's rmse: 1.32132\tvalid_1's rmse: 1.02041\n",
      "[250]\ttraining's rmse: 1.30682\tvalid_1's rmse: 1.01046\n",
      "[275]\ttraining's rmse: 1.29287\tvalid_1's rmse: 1.00121\n",
      "[300]\ttraining's rmse: 1.27945\tvalid_1's rmse: 0.992641\n",
      "[325]\ttraining's rmse: 1.26654\tvalid_1's rmse: 0.984741\n",
      "[350]\ttraining's rmse: 1.25412\tvalid_1's rmse: 0.977437\n",
      "[375]\ttraining's rmse: 1.24217\tvalid_1's rmse: 0.970748\n",
      "[400]\ttraining's rmse: 1.23065\tvalid_1's rmse: 0.964681\n",
      "[425]\ttraining's rmse: 1.21954\tvalid_1's rmse: 0.959208\n",
      "[450]\ttraining's rmse: 1.20887\tvalid_1's rmse: 0.954244\n",
      "[475]\ttraining's rmse: 1.19865\tvalid_1's rmse: 0.949733\n",
      "[500]\ttraining's rmse: 1.18881\tvalid_1's rmse: 0.945706\n",
      "[525]\ttraining's rmse: 1.17924\tvalid_1's rmse: 0.942159\n",
      "[550]\ttraining's rmse: 1.17005\tvalid_1's rmse: 0.939003\n",
      "[575]\ttraining's rmse: 1.16124\tvalid_1's rmse: 0.936242\n",
      "[600]\ttraining's rmse: 1.1528\tvalid_1's rmse: 0.933862\n",
      "[625]\ttraining's rmse: 1.14466\tvalid_1's rmse: 0.931832\n",
      "[650]\ttraining's rmse: 1.13681\tvalid_1's rmse: 0.930127\n",
      "[675]\ttraining's rmse: 1.1293\tvalid_1's rmse: 0.928756\n",
      "[700]\ttraining's rmse: 1.12211\tvalid_1's rmse: 0.927672\n",
      "[725]\ttraining's rmse: 1.11522\tvalid_1's rmse: 0.926884\n",
      "[750]\ttraining's rmse: 1.10861\tvalid_1's rmse: 0.926363\n",
      "[775]\ttraining's rmse: 1.10228\tvalid_1's rmse: 0.926104\n",
      "[800]\ttraining's rmse: 1.09622\tvalid_1's rmse: 0.926084\n",
      "Early stopping, best iteration is:\n",
      "[791]\ttraining's rmse: 1.09837\tvalid_1's rmse: 0.926064\n"
     ]
    }
   ],
   "source": [
    "model = lgb_model(params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "791\n"
     ]
    }
   ],
   "source": [
    "print(model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light GBM Meta Model Train (block 32) MSE:  1.2064141123142558\n",
      "Light GBM Meta Model Test (block 33) MSE:  0.8575943376305404\n"
     ]
    }
   ],
   "source": [
    "lgbm_meta_test_pred = model.predict(X_test_meta.values)\n",
    "lgbm_meta_train_pred = model.predict(X_train_meta.values)\n",
    "lgbm_meta_test_MSE = mean_squared_error(y_test_meta, lgbm_meta_test_pred.clip(0, 20))\n",
    "lgbm_meta_train_MSE = mean_squared_error(y_train_meta, lgbm_meta_train_pred.clip(0, 20))\n",
    "print('Light GBM Meta Model Train (block 32) MSE: ',lgbm_meta_train_MSE)\n",
    "print('Light GBM Meta Model Test (block 33) MSE: ',lgbm_meta_test_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb_meta_0201_21.13.txt\n"
     ]
    }
   ],
   "source": [
    "st = datetime.datetime.fromtimestamp(time.time()).strftime('%m%d_%H.%M')\n",
    "model.save_model('lgb_meta_' + st + '.txt', num_iteration= model.best_iteration)\n",
    "print('lgb_meta_' + st + '.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load models that are trained on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../script/'\n",
    "lrModel = joblib.load(DATA_FOLDER + 'lr_full_0201_21.06.pkl') \n",
    "lgbmModel = lgb.Booster(model_file ='lgb_model_full_0131_17.52.txt') \n",
    "nnModel = load_model(DATA_FOLDER + 'nn_full_model.h5')\n",
    "lgb_meta = lgb.Booster(model_file = DATA_FOLDER + 'lgb_meta_0201_21.13.txt')\n",
    "lr_meta = joblib.load(DATA_FOLDER + 'lr_meta_0201_21.09.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../data/'\n",
    "X_test_robustScaler = pd.read_pickle(DATA_FOLDER + 'X_test_RobustScaler') # LR\n",
    "X_test_standardScaler = pd.read_pickle(DATA_FOLDER + 'X_test_standardScaler') # NNet\n",
    "X_test_robustScalerTree = pd.read_pickle(DATA_FOLDER + 'X_test_RobustScalerTree') #light GBM\n",
    "X_test_robustScaler_lr = X_test_robustScaler.drop(['shop_id','item_id', 'item_category_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions for the base learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrFinalPred = lrModel.predict(X_test_robustScaler_lr).clip(0,20)\n",
    "lgbmFinalPred = lgbmModel.predict(X_test_robustScalerTree).clip(0,20)\n",
    "nnFinalPred = nnModel.predict(X_test_standardScaler).clip(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = pd.DataFrame(columns = ['lr', 'lgbm', 'nnet'])\n",
    "preds_test['lr'] = lrFinalPred\n",
    "preds_test['lgbm'] = lgbmFinalPred \n",
    "preds_test['nnet'] = nnFinalPred\n",
    "preds_test['mean'] = pd.DataFrame.mean(preds_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214200, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions for the meta learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrMetaPred = lr_meta.predict(preds_test).clip(0,20)\n",
    "lgbMetaPred = lgb_meta.predict(preds_test).clip(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_final_pred(pred):\n",
    "    ID = joblib.load('ID.pkl')\n",
    "    predDF = pd.DataFrame() \n",
    "    predDF['ID'] = ID\n",
    "    predDF['item_cnt_month'] = pred\n",
    "    ts = time.time()\n",
    "    st = datetime.datetime.fromtimestamp(ts).strftime('%m%d_%H.%M')\n",
    "    print('submission_' + st + '.csv')\n",
    "\n",
    "    predDF.to_csv(header=True, index=False, path_or_buf = 'submission_' + st + '.csv')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_0201_21.16.csv\n"
     ]
    }
   ],
   "source": [
    "submit_final_pred(lrMetaPred) # 1.00192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_0201_21.17.csv\n"
     ]
    }
   ],
   "source": [
    "submit_final_pred(lgbMetaPred) # 0.97329"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_0201_21.24.csv\n"
     ]
    }
   ],
   "source": [
    "submit_final_pred(preds_test['mean']) # 0.92366"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
